[2025-02-27T09:48:50.089+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:48:50.095+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:48:50.096+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T09:48:50.107+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T09:48:50.112+0000] {standard_task_runner.py:60} INFO - Started process 2035 to run task
[2025-02-27T09:48:50.114+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmp3o92m9ft']
[2025-02-27T09:48:50.115+0000] {standard_task_runner.py:88} INFO - Job 9: Subtask upload_to_clickhouse_task
[2025-02-27T09:48:50.139+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T09:48:50.187+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T09:48:50.189+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 92, in upload_to_clickhouse
    data_frame = pd.read_csv(csv_file)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'extracted_data_csv.csv'
[2025-02-27T09:48:50.194+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T094850, end_date=20250227T094850
[2025-02-27T09:48:50.202+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 9 for task upload_to_clickhouse_task ([Errno 2] No such file or directory: 'extracted_data_csv.csv'; 2035)
[2025-02-27T09:48:50.249+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T09:48:50.258+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T09:50:23.160+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:50:23.165+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:50:23.165+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T09:50:23.181+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T09:50:23.187+0000] {standard_task_runner.py:60} INFO - Started process 2263 to run task
[2025-02-27T09:50:23.190+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmp3ghu5mxw']
[2025-02-27T09:50:23.191+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T09:50:23.220+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T09:50:23.265+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T09:50:23.268+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 92, in upload_to_clickhouse
    data_frame = pd.read_csv(csv_file)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'extracted_data_csv.csv'
[2025-02-27T09:50:23.274+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T095023, end_date=20250227T095023
[2025-02-27T09:50:23.284+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task ([Errno 2] No such file or directory: 'extracted_data_csv.csv'; 2263)
[2025-02-27T09:50:23.323+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T09:50:23.332+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T09:54:42.399+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:54:42.405+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T09:54:42.405+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T09:54:42.418+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T09:54:42.424+0000] {standard_task_runner.py:60} INFO - Started process 2843 to run task
[2025-02-27T09:54:42.426+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpv7uymubv']
[2025-02-27T09:54:42.428+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T09:54:42.460+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T09:54:42.517+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T09:54:42.520+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 93, in upload_to_clickhouse
    data_frame = pd.read_csv(csv_file)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'extracted_data_csv.csv'
[2025-02-27T09:54:42.526+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T095442, end_date=20250227T095442
[2025-02-27T09:54:42.538+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task ([Errno 2] No such file or directory: 'extracted_data_csv.csv'; 2843)
[2025-02-27T09:54:42.561+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T09:54:42.570+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:06:34.893+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:06:34.898+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:06:34.899+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:06:34.914+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:06:34.919+0000] {standard_task_runner.py:60} INFO - Started process 3485 to run task
[2025-02-27T10:06:34.921+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpdqcrv73m']
[2025-02-27T10:06:34.923+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:06:34.953+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:06:35.004+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:06:35.007+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 87, in upload_to_clickhouse
    data_frame = pd.read_csv(csv_file)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'extracted_data_csv.csv'
[2025-02-27T10:06:35.013+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T100634, end_date=20250227T100635
[2025-02-27T10:06:35.025+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task ([Errno 2] No such file or directory: 'extracted_data_csv.csv'; 3485)
[2025-02-27T10:06:35.055+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:06:35.064+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:12:26.381+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:12:26.389+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:12:26.390+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:12:26.403+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:12:26.410+0000] {standard_task_runner.py:60} INFO - Started process 4098 to run task
[2025-02-27T10:12:26.415+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpa5399qoq']
[2025-02-27T10:12:26.417+0000] {standard_task_runner.py:88} INFO - Job 11: Subtask upload_to_clickhouse_task
[2025-02-27T10:12:26.463+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:12:26.532+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:12:26.537+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 88, in upload_to_clickhouse
    data_frame = pd.read_csv(csv_file)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
  File "/home/airflow/.local/lib/python3.9/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'extracted_data_csv.csv'
[2025-02-27T10:12:26.542+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T101226, end_date=20250227T101226
[2025-02-27T10:12:26.557+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 11 for task upload_to_clickhouse_task ([Errno 2] No such file or directory: 'extracted_data_csv.csv'; 4098)
[2025-02-27T10:12:26.590+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:12:26.600+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:14:12.406+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:14:12.410+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:14:12.411+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:14:12.420+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:14:12.424+0000] {standard_task_runner.py:60} INFO - Started process 4380 to run task
[2025-02-27T10:14:12.427+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpstpb9d3q']
[2025-02-27T10:14:12.428+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:14:12.452+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:14:12.490+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:14:12.497+0000] {connection.py:411} WARNING - Failed to connect to None:9000
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 399, in connect
    return self._init_connection(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 329, in _init_connection
    self.socket = self._create_socket(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 301, in _create_socket
    raise err
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 292, in _create_socket
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-02-27T10:14:12.497+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 90, in upload_to_clickhouse
    client.execute(f'CREATE TABLE IF NOT EXISTS {table_name} (source String, currency String, value Float, date String) ENGINE Log')
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 370, in execute
    with self.disconnect_on_error(query, settings):
  File "/usr/local/lib/python3.9/contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 313, in disconnect_on_error
    self.establish_connection(settings)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 300, in establish_connection
    self.connection.force_connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 258, in force_connect
    self.connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 420, in connect
    raise err
clickhouse_driver.errors.NetworkError: Code: 210. Connection refused (None:9000)
[2025-02-27T10:14:12.502+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T101412, end_date=20250227T101412
[2025-02-27T10:14:12.510+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task (Code: 210. Connection refused (None:9000); 4380)
[2025-02-27T10:14:12.520+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:14:12.528+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:19:26.460+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:19:26.467+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:19:26.468+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:19:26.481+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:19:26.487+0000] {standard_task_runner.py:60} INFO - Started process 4973 to run task
[2025-02-27T10:19:26.490+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmp6k8fsv08']
[2025-02-27T10:19:26.491+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:19:26.518+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:19:26.566+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:19:26.573+0000] {connection.py:411} WARNING - Failed to connect to None:9000
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 399, in connect
    return self._init_connection(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 329, in _init_connection
    self.socket = self._create_socket(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 301, in _create_socket
    raise err
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 292, in _create_socket
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-02-27T10:19:26.574+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 90, in upload_to_clickhouse
    client.execute(f'CREATE TABLE IF NOT EXISTS {table_name} (source String, currency String, value Float, date String) ENGINE Log')
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 370, in execute
    with self.disconnect_on_error(query, settings):
  File "/usr/local/lib/python3.9/contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 313, in disconnect_on_error
    self.establish_connection(settings)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 300, in establish_connection
    self.connection.force_connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 258, in force_connect
    self.connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 420, in connect
    raise err
clickhouse_driver.errors.NetworkError: Code: 210. Connection refused (None:9000)
[2025-02-27T10:19:26.581+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T101926, end_date=20250227T101926
[2025-02-27T10:19:26.593+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task (Code: 210. Connection refused (None:9000); 4973)
[2025-02-27T10:19:26.624+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:19:26.636+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:24:09.487+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:24:09.493+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:24:09.493+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:24:09.504+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:24:09.508+0000] {standard_task_runner.py:60} INFO - Started process 5426 to run task
[2025-02-27T10:24:09.510+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpkmw5mjnx']
[2025-02-27T10:24:09.512+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:24:09.536+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:24:09.575+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:24:09.580+0000] {connection.py:411} WARNING - Failed to connect to None:9000
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 399, in connect
    return self._init_connection(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 329, in _init_connection
    self.socket = self._create_socket(host, port)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 301, in _create_socket
    raise err
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 292, in _create_socket
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused
[2025-02-27T10:24:09.581+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 90, in upload_to_clickhouse
    client.execute(f'CREATE TABLE IF NOT EXISTS {table_name} (source String, currency String, value Float, date String) ENGINE Log')
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 370, in execute
    with self.disconnect_on_error(query, settings):
  File "/usr/local/lib/python3.9/contextlib.py", line 119, in __enter__
    return next(self.gen)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 313, in disconnect_on_error
    self.establish_connection(settings)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 300, in establish_connection
    self.connection.force_connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 258, in force_connect
    self.connect()
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/connection.py", line 420, in connect
    raise err
clickhouse_driver.errors.NetworkError: Code: 210. Connection refused (None:9000)
[2025-02-27T10:24:09.586+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T102409, end_date=20250227T102409
[2025-02-27T10:24:09.596+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task (Code: 210. Connection refused (None:9000); 5426)
[2025-02-27T10:24:09.604+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:24:09.613+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:26:53.298+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:26:53.304+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:26:53.304+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:26:53.316+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:26:53.321+0000] {standard_task_runner.py:60} INFO - Started process 5715 to run task
[2025-02-27T10:26:53.324+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpia3305n2']
[2025-02-27T10:26:53.325+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:26:53.369+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:26:53.430+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:26:53.446+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 92, in upload_to_clickhouse
    client.execute(f'INSERT INTO {table_name} VALUES', data_frame.to_dict('records'))
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 376, in execute
    rv = self.process_insert_query(
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 607, in process_insert_query
    rv = self.send_data(sample_block, data,
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 658, in send_data
    block = block_cls(sample_block.columns_with_types, chunk,
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 40, in __init__
    self.data = self.normalize(data or [])
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 128, in normalize
    self._mutate_dicts_to_rows(data)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 159, in _mutate_dicts_to_rows
    return self._pure_mutate_dicts_to_rows(
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 186, in _pure_mutate_dicts_to_rows
    new_data.append(row[name])
KeyError: 'source'
[2025-02-27T10:26:53.454+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T102653, end_date=20250227T102653
[2025-02-27T10:26:53.464+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task ('source'; 5715)
[2025-02-27T10:26:53.498+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:26:53.507+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:35:14.437+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:35:14.442+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:35:14.442+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:35:14.454+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:35:14.459+0000] {standard_task_runner.py:60} INFO - Started process 6375 to run task
[2025-02-27T10:35:14.461+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpoxp9mmf5']
[2025-02-27T10:35:14.463+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:35:14.489+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:35:14.528+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:35:14.540+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/3_4_2_homework_assignment.py", line 93, in upload_to_clickhouse
    client.execute(f'INSERT INTO {table_name} VALUES', data_frame.to_dict('records'))
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 376, in execute
    rv = self.process_insert_query(
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 607, in process_insert_query
    rv = self.send_data(sample_block, data,
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/client.py", line 658, in send_data
    block = block_cls(sample_block.columns_with_types, chunk,
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 40, in __init__
    self.data = self.normalize(data or [])
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 128, in normalize
    self._mutate_dicts_to_rows(data)
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 159, in _mutate_dicts_to_rows
    return self._pure_mutate_dicts_to_rows(
  File "/home/airflow/.local/lib/python3.9/site-packages/clickhouse_driver/block.py", line 186, in _pure_mutate_dicts_to_rows
    new_data.append(row[name])
KeyError: 'source'
[2025-02-27T10:35:14.546+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T103514, end_date=20250227T103514
[2025-02-27T10:35:14.554+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 13 for task upload_to_clickhouse_task ('source'; 6375)
[2025-02-27T10:35:14.596+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-02-27T10:35:14.605+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-02-27T10:45:06.663+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:45:06.670+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [queued]>
[2025-02-27T10:45:06.671+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2025-02-27T10:45:06.685+0000] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): upload_to_clickhouse_task> on 2024-01-04 00:00:00+00:00
[2025-02-27T10:45:06.690+0000] {standard_task_runner.py:60} INFO - Started process 7060 to run task
[2025-02-27T10:45:06.692+0000] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', '3_4_2_homework_assignment', 'upload_to_clickhouse_task', 'scheduled__2024-01-04T00:00:00+00:00', '--job-id', '13', '--raw', '--subdir', 'DAGS_FOLDER/3_4_2_homework_assignment.py', '--cfg-path', '/tmp/tmpitd9kjoi']
[2025-02-27T10:45:06.694+0000] {standard_task_runner.py:88} INFO - Job 13: Subtask upload_to_clickhouse_task
[2025-02-27T10:45:06.719+0000] {task_command.py:423} INFO - Running <TaskInstance: 3_4_2_homework_assignment.upload_to_clickhouse_task scheduled__2024-01-04T00:00:00+00:00 [running]> on host ea5964584459
[2025-02-27T10:45:06.765+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='3_4_2_homework_assignment' AIRFLOW_CTX_TASK_ID='upload_to_clickhouse_task' AIRFLOW_CTX_EXECUTION_DATE='2024-01-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-01-04T00:00:00+00:00'
[2025-02-27T10:45:06.780+0000] {unix.py:142} WARNING - /etc/timezone is deprecated on Debian, and no longer reliable. Ignoring.
[2025-02-27T10:45:06.783+0000] {python.py:201} INFO - Done. Returned value was: None
[2025-02-27T10:45:06.786+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=3_4_2_homework_assignment, task_id=upload_to_clickhouse_task, execution_date=20240104T000000, start_date=20250227T104506, end_date=20250227T104506
[2025-02-27T10:45:06.828+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-02-27T10:45:06.836+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
